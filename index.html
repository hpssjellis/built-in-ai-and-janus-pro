

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Description with Chrome Built-in API</title>





  
    <script type="module">
        const myImageInput = document.getElementById('myImageInput');
        const myImagePreview = document.getElementById('myImagePreview');
        const myOutputText = document.getElementById('myOutputText');
        const myStatus = document.getElementById('myStatus');
        const myWebcamPreview = document.getElementById('myWebcamPreview');
        const myCaptureImageButton = document.getElementById('myCaptureImageButton');
        const myDescribeButton = document.getElementById('myDescribeButton');
        const myStopButton = document.getElementById('myStopButton');
        const myCanvas = document.getElementById('myCanvas');
        let myImageBlob = null;
        let myTimerId = null;
        let myAnalysisTimerId = null;
        let myAbortController = null;
        let myTimeoutId = null;
        myImageInput.onchange = async (event) => {
            const myFile = event.target.files[0];
            if (myFile) {
                myImageBlob = myFile;
                myImagePreview.src = URL.createObjectURL(myFile);
                myImagePreview.style.display = 'block';
                myWebcamPreview.style.display = 'none';
                myCaptureImageButton.style.display = 'none';
                myOutputText.textContent = 'Ready to describe...';
                myStatus.textContent = '';
            }
        };
        window.myStartWebcam = async () => {
            try {
                const myStream = await navigator.mediaDevices.getUserMedia({ video: true });
                myWebcamPreview.srcObject = myStream;
                myWebcamPreview.style.display = 'block';
                myWebcamPreview.play();
                myCaptureImageButton.style.display = 'block';
                myImageInput.style.display = 'none';
                myImagePreview.style.display = 'none';
                myOutputText.textContent = 'Webcam active. Click "Capture Image" to continue.';
                myImageBlob = null;
            } catch (error) {
                myOutputText.textContent = 'Error starting webcam: ' + error.message;
            }
        };
        window.myCaptureImage = () => {
            myCanvas.width = myWebcamPreview.videoWidth;
            myCanvas.height = myWebcamPreview.videoHeight;
            const myContext = myCanvas.getContext('2d');
            myContext.drawImage(myWebcamPreview, 0, 0, myCanvas.width, myCanvas.height);
            myCanvas.toBlob((myBlob) => {
                myImageBlob = myBlob;
                myImagePreview.src = URL.createObjectURL(myBlob);
                myImagePreview.style.display = 'block';
                myWebcamPreview.pause();
                myWebcamPreview.srcObject.getTracks().forEach(track => track.stop());
                myWebcamPreview.style.display = 'none';
                myCaptureImageButton.style.display = 'none';
                myImageInput.style.display = 'block';
                myOutputText.textContent = 'Image captured. Ready to describe...';
            }, 'image/jpeg');
        };
        window.myStopDescription = () => {
            if (myAbortController) {
                myAbortController.abort();
                myAbortController = null;
            }
            clearInterval(myTimerId);
            clearInterval(myAnalysisTimerId);
            clearTimeout(myTimeoutId);
            myStatus.textContent = 'Process stopped.';
            myDescribeButton.disabled = false;
            myStopButton.style.display = 'none';
        };
        window.myStartDescription = async () => {
            if (!myImageBlob) {
                myOutputText.textContent = 'Please select or capture an image first.';
                return;
            }
            myDescribeButton.disabled = true;
            myStopButton.style.display = 'block';
            myAbortController = new AbortController();
            let mySeconds = 0;
            myOutputText.textContent = 'Model is being downloaded...';
            myTimerId = setInterval(() => {
                mySeconds++;
                myOutputText.textContent = `Model is being downloaded... ${mySeconds} seconds`;
            }, 1000);
            myTimeoutId = setTimeout(() => {
                if (myAbortController) {
                    myAbortController.abort();
                }
            }, 120000); // 120 second timeout
            try {
                // Log information about the AI model before creation
                console.log('Attempting to create a Language Model session with expected image inputs.');
                const mySession = await LanguageModel.create({
                    expectedInputs: [{ type: 'image' }],
                });
                // Log information after the session is successfully created
                console.log('Language Model session created successfully. Ready for prompt streaming.');
                clearInterval(myTimerId);
                myOutputText.textContent = '';
                let myAnalysisSeconds = 0;
                myAnalysisTimerId = setInterval(() => {
                    myAnalysisSeconds++;
                    myStatus.textContent = `Analyzing... ${myAnalysisSeconds} seconds`;
                }, 1000);
                // Log the prompt being sent to the model
                console.log('Sending prompt to the model: "Describe this image as completely as you can in a prompt form so that an image generator can reproduce the image"');
                const myStream = mySession.promptStreaming([
                    {
                        role: 'user',
                        content: [
                            {
                                type: 'image',
                                value: myImageBlob,
                            },
                            {
                                type: 'text',
                                value: 'Describe this image as completely as you can in a prompt form so that an image generator can reproduce the image',
                            },
                        ],
                    },
                ], { signal: myAbortController.signal });
                for await (const myChunk of myStream) {
                    myOutputText.append(myChunk);
                }
                clearInterval(myAnalysisTimerId);
                clearTimeout(myTimeoutId);
                myStatus.textContent = 'Analysis complete.';

              // send to Janus-Pro and activate
/*

<textarea id="myArea01" rows="5" cols="70" placeholder="Ask your question here">/imagine A stunning princess from Kabul in red, white traditional clothing, blue eyes, brown hair</textarea><br>
<!-- Max tokens in the answer: <input id="myMaxTokens" type=number style="width:60px" value="512">  -->
<input id="myAskButton" type="button" value="Generate Image From Text" onclick="myMain()"  disabled><br><br>

              */
               document.getElementById('myArea01').value =  '/imagine ' +  myOutputText.textContent
               await myLoadModel()
               myMain()
              
                // Log when the description is finished
                console.log('Description finished. Output is now on the page.');
            } catch (error) {
                clearInterval(myTimerId);
                clearInterval(myAnalysisTimerId);
                clearTimeout(myTimeoutId);
                if (error.name === 'AbortError') {
                    myStatus.textContent = 'Description process was stopped.';
                    console.error('The user aborted the process.');
                } else {
                    myStatus.textContent = 'An error occurred. Please check the console for details.';
                    console.error('An error occurred during the model interaction:', error);
                }
            } finally {
                myAbortController = null;
                myDescribeButton.disabled = false;
                myStopButton.style.display = 'none';
            }
        };
    </script>






  
<script type="module">





  

  
import { AutoProcessor, MultiModalityCausalLM, } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.5.1';

  // needed for module functions to be called from buttons
window.myLoadModel = myLoadModel
window.myMain = myMain

// make these global so the functions can share data.  
let myProcessor
let myJanusProModel

// Define constants
const IMAGE_GENERATION_COMMAND_PREFIX = "/imagine ";
const MAX_NEW_TEXT_TOKENS = 1024;
let fp16_supported = false;


/**
 * Check WebGPU support
 */
async function checkWebGPU() {
  try {
    const adapter = await navigator.gpu.requestAdapter();
    fp16_supported = adapter && adapter.features.has("shader-f16");
  } catch (e) {
    console.error("WebGPU not supported:", e);
  }
}

/**
 * Load model and processor
 */
async function myLoadModel() {
  let myModelName = document.getElementById('myModelInput').value
  await checkWebGPU();
  //const model_id = "onnx-community/Janus-Pro-1B-ONNX";
  
  myProcessor = await AutoProcessor.from_pretrained(myModelName);
  myJanusProModel = await MultiModalityCausalLM.from_pretrained(myModelName, {
      dtype: fp16_supported
        ? {
            prepare_inputs_embeds: "q4",
            language_model: "q4f16",
            lm_head: "fp16",
            gen_head: "fp16",
            gen_img_embeds: "fp16",
            image_decode: "fp32",
          }
        : {
            prepare_inputs_embeds: "fp32",
            language_model: "q4",
            lm_head: "fp32",
            gen_head: "fp32",
            gen_img_embeds: "fp32",
            image_decode: "fp32",
          },
      device: {
        prepare_inputs_embeds: "wasm", // TODO use "webgpu" when bug is fixed
        language_model: "webgpu",
        lm_head: "webgpu",
        gen_head: "webgpu",
        gen_img_embeds: "webgpu",
        image_decode: "webgpu",
      },
    //  progress_callback,
    });
     // return Promise.all([processor, model]);
  
      document.getElementById('myLoadButton').disabled = true
      document.getElementById('myAskButton').disabled = false
      return { myProcessor, myJanusProModel };
  }


  /*
  const model = await MultiModalityCausalLM.from_pretrained(model_id, {
    //dtype: fp16_supported ? "fp16" : "fp32",                                // "q4", "q8", "q4f16",  "fp16" : "fp32",      
    dtype: "q4f16",                               // "q4", "q8", "q4f16",  "fp16" : "fp32",      
    device: "webgpu"     // device: "wasm"
  });
  
  return { myProcessor, model };
}

*/

  
/**
 * Generate an image from text prompt
 */
async function generateImage(prompt, myProcessor, myJanusProModel) {
  if (!prompt.startsWith(IMAGE_GENERATION_COMMAND_PREFIX)) return;
  
  const text = prompt.replace(IMAGE_GENERATION_COMMAND_PREFIX, "");
  const conversation = [{ role: "<|User|>", content: text }];
  const inputs = await myProcessor(conversation, { chat_template: "text_to_image" });
  
  const num_image_tokens = myProcessor.num_image_tokens;
  const outputs = await myJanusProModel.generate_images({
    ...inputs,
    min_new_tokens: num_image_tokens,
    max_new_tokens: num_image_tokens,
    do_sample: true,
  });
  
  return outputs[0];
}



  async function myMain() {

    console.log("Generate Image...");
    let myPrompt = document.getElementById('myArea01').value 
   // const prompt = "/imagine A stunning princess from Kabul in red, white traditional clothing, blue eyes, brown hair";
    const image = await generateImage(myPrompt, myProcessor, myJanusProModel);
  
    console.log("Image generated, now putting on the webpage");
    if (image) {
      const blob = await image.toBlob();
      const imgUrl = URL.createObjectURL(blob);
      document.getElementById('myOutputImage').src = imgUrl;
    
   // const imgElement = document.createElement("img");
   // imgElement.src = imgUrl;
   // document.body.appendChild(imgElement);

    }  
    console.log("Image on webpage");
  }
    


</script>
</head>
<body>
    <h1>Chrome Built-In API Image Description</h1>
    <p>Select an image, or use your webcam to capture one, to describe it using the Language Model API.</p>
    <input type="file" id="myImageInput" accept="image/*" />
    <button onclick="myStartWebcam()">Start Webcam</button>
    <button id="myCaptureImageButton" onclick="myCaptureImage()" style="display: none;">Capture Image</button>
    <button id="myDescribeButton" onclick="myStartDescription()">Describe Image</button>
    <button id="myStopButton" onclick="myStopDescription()" style="display: none;">Stop Description</button>
    <div id="myStatus">Status here</div>
    <h2>Description:</h2>
    <p id="myOutputText"></p>
    <img id="myImagePreview" alt="Image Preview" style="display: none; max-width: 100%; height: auto;" />
    <video id="myWebcamPreview" style="display: none; max-width: 100%; height: auto;"></video>
    <canvas id="myCanvas" style="display: none;"></canvas>



<h1>Janus-Pro text to Image based on DeepSeek-R1-webgpu in the browser</h1>
  
Open the console. shift-ctrl-i <br><br>
  
Fully javascript activated. If you don't want to completely download 
<a href="https://huggingface.co/onnx-community/Janus-Pro-1B-ONNX"> 
onnx-community/Janus-Pro-1B-ONNX </a> then you should probably close this page.<br><br>
It will load from cache if downloaded once. If you first download this single weebpage and download the model it will work offline<br><br>

Uses the Web-gpu model or other models: <input id="myModelInput" type=text size=60 value="onnx-community/Janus-Pro-1B-ONNX"> <br><br>

<input id="myLoadButton" type="button" value="Load Model" onclick="myLoadModel()"> Data warning ~2.4 GB saved to cache<br><br>  
<textarea id="myArea01" rows="5" cols="70" placeholder="Ask your question here">/imagine A stunning princess from Kabul in red, white traditional clothing, blue eyes, brown hair</textarea><br>
<!-- Max tokens in the answer: <input id="myMaxTokens" type=number style="width:60px" value="512">  -->
<input id="myAskButton" type="button" value="Generate Image From Text" onclick="myMain()"  disabled><br><br>

<!--<textarea id="myTextarea01"  rows="20" cols="95%" placeholder="Reply Goes here" READONLY></textarea><br><br> -->
  <!--
<input type=button value="copy" onclick="{  
  let myTextarea = document.getElementById('myTextarea01');
  myTextarea.select(); 
  document.execCommand('copy'); // Copy to clipboard
}"><br>  -->
Use at your own risk, by <a href="https://www.linkedin.com/in/jeremy-ellis-4237a9bb/">Jeremy Ellis LinkedIn</a><br> 
Github index at <a href="https://hpssjellis.github.io/my-examples-of-ai-agents/public/index.html">hpssjellis.github.io/my-examples-of-ai-agents/public/index.html</a><br>
My transformersjs github where the work was done <a href="https://github.com/hpssjellis/my-examples-of-transformersJS">https://github.com/hpssjellis/my-examples-of-transformersJS</a><br>
My Github <a href="https://github.com/hpssjellis">Profile</a><br>
<h2>Image here, expect a delay</h2>
<img src="" id="myOutputImage" width= "95%" style="border-Color:blue; border-style:groove; border-width:3px; "><br><br>
</body>
</html>




